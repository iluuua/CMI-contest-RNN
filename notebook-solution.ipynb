{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, json, numpy as np, pandas as pd, polars as pl, joblib, torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "COMP_DIR = \"/kaggle/input/cmi-detect-behavior-with-sensor-data\"\n",
    "ART_DIR = \"/kaggle/input/model_cmi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pad_to_len(X, pad_len, pad_mode=\"post\", trunc_mode=\"post\", value=0.0):\n",
    "    X = np.asarray(X, dtype=np.float32); T, C = X.shape\n",
    "    if T == pad_len: \n",
    "        return X.copy()\n",
    "    if T > pad_len:\n",
    "        if trunc_mode == \"post\": out = X[:pad_len]\n",
    "        elif trunc_mode == \"pre\": out = X[-pad_len:]\n",
    "        else: start = (T - pad_len)//2; out = X[start:start+pad_len]\n",
    "        return out.astype(np.float32, copy=False)\n",
    "    \n",
    "    pad_total = pad_len - T\n",
    "    if pad_mode == \"post\": \n",
    "        pb, pa = 0, pad_total\n",
    "    elif pad_mode == \"pre\": \n",
    "        pb, pa = pad_total, 0\n",
    "    else: \n",
    "        pb = pad_total//2\n",
    "        pa = pad_total - pb\n",
    "        \n",
    "    return np.pad(X, ((pb,pa),(0,0)), constant_values=value).astype(np.float32, copy=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21411acc3984e252"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class AttnPool(nn.Module):\n",
    "    def __init__(self, dim, dropout=0.1):\n",
    "        super().__init__() \n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.v = nn.Linear(dim,1,bias=False) \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, H, mask=None):\n",
    "        e = self.v(torch.tanh(self.proj(H))).squeeze(-1)\n",
    "        if mask is not None: \n",
    "            e = e.masked_fill(~mask, float(\"-inf\"))\n",
    "        w = torch.softmax(e, dim=1).unsqueeze(-1)\n",
    "        \n",
    "        return self.drop((H*w).sum(1)), w.squeeze(-1)\n",
    "\n",
    "class RNNWithAttn(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, rnn_type=\"lstm\", hidden_size=128, num_layers=2, bidirectional=True, input_dropout=0.1, attn_dropout=0.1, fc_dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.in_drop = nn.Dropout(input_dropout)\n",
    "        rnn = nn.LSTM if rnn_type.lower() == \"lstm\" else nn.GRU\n",
    "        self.rnn = rnn(input_dim, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional, dropout=0.0 if num_layers==1 else 0.1)\n",
    "        d = hidden_size*(2 if bidirectional else 1)\n",
    "        self.attn = AttnPool(d, dropout=attn_dropout)\n",
    "        self.head = nn.Sequential(nn.Linear(d,d), nn.ReLU(), nn.Dropout(fc_dropout), nn.Linear(d, num_classes))\n",
    "        \n",
    "    def forward(self, x_pad, lengths):\n",
    "        x = self.in_drop(x_pad)\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.rnn(packed)\n",
    "        H, _ = pad_packed_sequence(packed_out, batch_first=True, total_length=x_pad.size(1))\n",
    "        idx = torch.arange(x_pad.size(1), device=x_pad.device).unsqueeze(0)\n",
    "        mask = idx < lengths.unsqueeze(1)\n",
    "        ctx, _ = self.attn(H, mask=mask)\n",
    "        return self.head(ctx)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d356e84497ca4fc4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(os.path.join(ART_DIR,\"meta.json\")) as f: meta = json.load(f)\n",
    "with open(os.path.join(ART_DIR,\"id2label.json\")) as f: id2label = {int(k):v for k,v in json.load(f).items()}\n",
    "scaler = joblib.load(os.path.join(ART_DIR,\"scaler.pkl\"))\n",
    "feat_cols = meta[\"feat_cols\"]; pad_len = int(meta[\"pad_len\"])\n",
    "\n",
    "model = RNNWithAttn(input_dim=len(feat_cols), num_classes=len(id2label))\n",
    "state = torch.load(os.path.join(ART_DIR,\"model_state_dict.pt\"), map_location=device)\n",
    "model.load_state_dict(state); model.to(device).eval()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee77f4be06f86ff3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _prep_seq(seq_pl: pl.DataFrame):\n",
    "    if isinstance(seq_pl, pl.LazyFrame): \n",
    "        seq_pl = seq_pl.collect()\n",
    "    df = seq_pl.to_pandas()\n",
    "    X = df[feat_cols].to_numpy(dtype=np.float32)\n",
    "    X = scaler.transform(X)\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32, copy=False)\n",
    "    L = min(X.shape[0], pad_len)\n",
    "    X = pad_to_len(X, pad_len, \"post\", \"post\")\n",
    "    xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
    "    Lb = torch.tensor([L], dtype=torch.long, device=device)\n",
    "    return xb, Lb\n",
    "\n",
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    xb, Lb = _prep_seq(sequence)\n",
    "    with torch.inference_mode():\n",
    "        logits = model(xb, Lb)\n",
    "        idx = int(torch.softmax(logits, -1).argmax(1).item())\n",
    "    return id2label[idx]\n",
    "\n",
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a83dce6928c7017"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            f\"{COMP_DIR}/test.csv\",\n",
    "            f\"{COMP_DIR}/test_demographics.csv\",\n",
    "        )\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44869c8f8b9587f7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
